{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6087aa09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/16971921/.conda/envs/py38_venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn        # модуль, где определены слои для нейронных сетей\n",
    "import torch.functional as F # модуль, где определены активации для слоев нейронных сетей\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchsummary import summary\n",
    "from ignite.metrics import Accuracy\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc981e",
   "metadata": {},
   "source": [
    "### датасет из kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5562a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kaggle\n",
    "# !kaggle datasets download \"kmader/skin-cancer-mnist-ham10000\"\n",
    "\n",
    "# Разархивируем датасет\n",
    "# !unzip skin-cancer-mnist-ham10000.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8908ffaf",
   "metadata": {},
   "source": [
    "### тренировка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105906bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# чистим кэш\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2151efba",
   "metadata": {},
   "source": [
    "Определяем класс ранней остановки (остановит обучение модели, когда валидационные потери не будут улучшаться после заданного количества эпох)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when monitored metric decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Monitored metric has improved ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), f'/content/drive/MyDrive/skinmodel50.pt') \n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92de9518",
   "metadata": {},
   "source": [
    "Определяем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f4500",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' \n",
    "\n",
    "model = models.resnet50(pretrained=True).to(device)\n",
    "\n",
    "model.fc = nn.Linear(2048, 7).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.0001)\n",
    "\n",
    "epochs = 80 #у нас будет ранняя остановка, поэтому кол-во эпох должно быть большое (изначально было 500) \n",
    "\n",
    "writer = SummaryWriter(log_dir='/content/drive/MyDrive/skin_logs/', filename_suffix=\"skin50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b065a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Информация о модели\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c27a2e",
   "metadata": {},
   "source": [
    "обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66568e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=50, verbose=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.00\n",
    "    val_loss = 0.00\n",
    "    train_accuracy = Accuracy()\n",
    "    val_accuracy = Accuracy()\n",
    "    print(f'Epoch {epoch+1}')\n",
    "\n",
    "    # Training loop\n",
    "    for idx, (inputs, labels) in enumerate(Bar(train_loader)):\n",
    "        model.train()\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad() \n",
    "        outputs = model(inputs) \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        train_loss += loss.item()\n",
    "        train_accuracy.update((nn.functional.softmax(outputs, dim=1), labels))\n",
    "    print(f\"Train Accuracy: {train_accuracy.compute()}\")\n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss_formated = \"{:.4f}\".format(train_loss)\n",
    "\n",
    "    # Validation loop\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            model.eval()           \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            val_accuracy.update((nn.functional.softmax(outputs, dim=1), labels))\n",
    "    print(f\"Val Accuracy: {val_accuracy.compute()}\")\n",
    "    val_loss /= len(val_loader)\n",
    "    val_loss_formated = \"{:.4f}\".format(val_loss)\n",
    "    print(f'Training Loss: {train_loss_formated}')\n",
    "    print(f\"Validation Loss: {val_loss_formated}\")\n",
    "\n",
    "    # TensorBoard writer \n",
    "    writer.add_scalar('Loss/train', train_loss, epoch+1)\n",
    "    writer.add_scalar('Loss/val', val_loss, epoch+1)\n",
    "    writer.add_scalar('Accuracy/train', train_accuracy.compute(), epoch+1)\n",
    "    writer.add_scalar('Accuracy/val', val_accuracy.compute(), epoch+1)\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stopping(val_loss, model)       \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "        \n",
    "# load the last checkpoint with the best model\n",
    "model.load_state_dict(torch.load('/content/drive/MyDrive/skinmodel50.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce642c4c",
   "metadata": {},
   "source": [
    "### результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d90499",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "\n",
    "predlist = torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "lbllist = torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "predlistauc = torch.zeros(0,dtype=torch.long, device='cpu')\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(val_loader):\n",
    "        model.eval()\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Append batch prediction results\n",
    "        predlist=torch.cat([predlist,preds.view(-1).cpu()])\n",
    "        lbllist=torch.cat([lbllist,classes.view(-1).cpu()])\n",
    "        predlistauc = torch.cat([predlistauc,nn.functional.softmax(outputs, dim=1).cpu()])\n",
    "predlist = predlist.numpy()\n",
    "lbllist = lbllist.numpy()\n",
    "predlistauc = predlistauc.numpy()\n",
    "\n",
    "# Classification report and AUC\n",
    "conf_mat=confusion_matrix(lbllist, predlist)\n",
    "target_names = ['MEL','NV','BCC','AKIEC','BKL','DF','VASC',]\n",
    "ConfusionMatrixDisplay(conf_mat, display_labels=target_names).plot(values_format=\"d\")\n",
    "print(classification_report(lbllist, predlist, target_names=target_names))\n",
    "lbllist_one_hot = nn.functional.one_hot(torch.tensor([lbllist]), num_classes=num_classes)\n",
    "every_auc = roc_auc_score(lbllist_one_hot.view([predlistauc.shape[0], predlistauc.shape[1]]), \n",
    "                                          predlistauc, multi_class='ovr', average=None)\n",
    "for i, every in enumerate(target_names):\n",
    "    print(f'AUC of class {every} = {every_auc[i]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
