{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "no0ZOM64dxCh"
   },
   "source": [
    "## Advanced Tensorflow Tutorial\n",
    "\n",
    "![img](https://github.com/yandexdataschool/nlp_course/raw/master/resources/tf_birds_bees.png)\n",
    "\n",
    "A highly subjective list of cool stuff about tensorflow that didn't fit into basic tutorial.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UjSXxeTXdxDw"
   },
   "source": [
    "## Part I: Debugging tensorflow\n",
    "\n",
    "Tensorflow error messages are hideous monstrosities with a heart of gold :)\n",
    "\n",
    "If your code breaks, TF will throw a wall of text your way. But you shouldn't be afraid of it. The key skill here is finding the part of error that actually matters: your code. Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fvRgOgRnO6Ra"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "keras, L = tf.keras, tf.keras.layers\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "embeddings = tf.Variable(np.random.randn(16, 10).astype('float32'))\n",
    "\n",
    "sequence_ids = tf.placeholder('int32')\n",
    "sequence_emb = tf.gather(embeddings, sequence_ids)\n",
    "mean_emb = tf.reduce_mean(sequence_emb, axis=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2201
    },
    "colab_type": "code",
    "id": "gc082MRn6bAu",
    "outputId": "c01ba803-a193-4b1f-b822-25187e0bac88"
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(mean_emb, {sequence_ids: np.random.randint(32, size=[3, 20])})\n",
    "sess.run(mean_emb, {sequence_ids: np.random.randint(32, size=20)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wdiIm4NQR2X7"
   },
   "source": [
    "Okay, here's what you should see\n",
    "* First and most important, this is just a traceback. No need to freak out. Keep calm.\n",
    "* Second, it tells us which sess.run caused an error - the second one. Here's the relevant part\n",
    "```\n",
    "        1 sess.run(tf.global_variables_initializer())\n",
    "        2 sess.run(mean_emb, {sequence_ids: np.random.randint(32, size=[3, 20])})\n",
    "----> 3 sess.run(mean_emb, {sequence_ids: np.random.randint(32, size=20)})\n",
    "```\n",
    "\n",
    "*  Then it tells us which line broke down:\n",
    "```\n",
    "  File \"<ipython-input-76-a9559652841a>\", line 11, in <module>\n",
    "    mean_emb = tf.reduce_mean(sequence_emb, axis=2)\n",
    "```\n",
    "* And the error\n",
    "```\n",
    "Invalid reduction dimension (2 for input with 2 dimension(s)\n",
    "```\n",
    "\n",
    "This information should already be sufficient ot find out what happened: we took 1d indices, mapped them to 2d embeddings and now want to averate over axis 2, but embeddings only got axes [0, 1].\n",
    "\n",
    "Let's try a few more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zFLy9iO2T6tK",
    "outputId": "1167b04f-aaaf-4f68-a519-eb4147f3b1f3"
   },
   "outputs": [],
   "source": [
    "%%writefile my_rnn_library.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def my_rnn(x_emb, emb_size, hid_size):\n",
    "    \"\"\" takes x_emb[time, batch, emb_size] and predicts\"\"\"\n",
    "    W = tf.Variable(np.random.randn(emb_size + hid_size, hid_size).astype('float32'),)\n",
    "    h0 = tf.zeros([tf.shape(x_emb)[1], hid_size])\n",
    "    \n",
    "    def scan_step(h_t, x_t):\n",
    "      rnn_inp = tf.concat([h_t, x_t], axis=1)\n",
    "      h_next = tf.tanh(tf.matmul(x_t, W))\n",
    "      return h_next\n",
    "      \n",
    "\n",
    "    return tf.scan(scan_step, elems=x_emb, initializer=h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "kIFI5RdCVOCd",
    "outputId": "a887a31a-7abf-4d25-8b95-973a2c2af1ab"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# ^-- an extension that reloads .py modules if you change their code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2427
    },
    "colab_type": "code",
    "id": "MmK5qdwBkBG2",
    "outputId": "7ab3c378-df8b-4583-fb09-1bec36c707df"
   },
   "outputs": [],
   "source": [
    "import my_rnn_library\n",
    "x = tf.placeholder('float32', [None, None, None])\n",
    "h = my_rnn_library.my_rnn(x, emb_size=32, hid_size=128)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(h, {x: np.random.randn(10, 3, 32)})\n",
    "\n",
    "# spoiler: its gonna fail. Your task is to understand what operation failed and how to fix that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "924Bk61G6crK"
   },
   "source": [
    "### Debugging tensorflow: invalid values\n",
    "\n",
    "If your code fails with an error, it's easy to find out what's wrong. However, sometimes there's no error, but your network doesn't train and your loss is equal to NaN or -inf. Or mean squared error is negative. Or ... well, you just know it's wrong.\n",
    "\n",
    "The question is: where is it wrong. There are two strategies: using tf.asserts and good old tinkering. We'll try the old way.\n",
    "\n",
    "The next example contains two errors:\n",
    "* an error with shapes that causes tensorflow \n",
    "* an error that causes tensorflow to return NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JkqXcAcPZxNq"
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder_with_default(np.random.randn(3, 15, 100).astype('float32'),\n",
    "                                [None, None, 100])\n",
    "x_len = tf.placeholder_with_default(np.array([3, 14, 8], dtype='int32'), [None])\n",
    "\n",
    "logits = L.Dense(256)(x)\n",
    "\n",
    "mask = tf.sequence_mask(x_len, dtype=tf.float32)\n",
    "\n",
    "\n",
    "logits = logits - (1 - mask)[:, :, None] * 1e9\n",
    "\n",
    "probs = tf.nn.softmax(logits, axis=1)\n",
    "\n",
    "mean_logp = tf.log(tf.reduce_mean(probs, axis=-1))\n",
    "\n",
    "mean_prob = tf.exp(mean_logp)\n",
    "\n",
    "grads = tf.gradients(mean_prob, [x])[0]\n",
    "\n",
    "grad_norms = tf.reduce_sum(grads ** 2, axis=(1, 2)) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3weRUo-fiV-Z",
    "outputId": "74ca7a8c-c925-4aff-f97c-f6c8726943a5"
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(grad_norms)\n",
    "\n",
    "# Your quest is as usual: find where's Waldo (NaN). And eliminate it :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zdEfFu_LdxD0"
   },
   "source": [
    "## Part II: Cool tensorflow features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v9VPM0_udxDG"
   },
   "outputs": [],
   "source": [
    "# for the next section we'll need to reload tensorflow without eager\n",
    "# PLEASE RESTART THE NOTEBOOK! (kernel-restart in jupyter, runtime -> restart in colab)\n",
    "# also if you're in colab, please request GPU-enabled runtime (settings -> notebook settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x-v9vFlPdxCo"
   },
   "source": [
    "### 1. Tensorflow Eager\n",
    "\n",
    "When you've first seen tensorflow in action, there was a lot of complicated stuff happening: defining operations on placeholders, sessions, variable initializers, etc.\n",
    "\n",
    "Luckily, TF also allows you to write code on the fly much the same way as you did in numpy. It's called __Tensorflow Eager__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCOc0ejUdxCs"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HinMpwLwd7e0"
   },
   "outputs": [],
   "source": [
    "# use tensorflow operations like you would use numpy\n",
    "x = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
    "y = tf.matmul(x, tf.random_normal([2, 4]))\n",
    "z = tf.nn.softmax(y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "77ovb3kXeIC_",
    "outputId": "8144cbb6-53db-4b64-8da7-8282575a0c41"
   },
   "outputs": [],
   "source": [
    "# every tensor has a value (like numpy arrays)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "CHm8jw-4eXcY",
    "outputId": "f0bd7945-050e-4e9f-91fe-c08bbca36dca"
   },
   "outputs": [],
   "source": [
    "# ... and can be converted to numpy\n",
    "z.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "kiNpNZfXeY8W",
    "outputId": "0c27ccad-f11e-4156-8172-0b38b10cd5a7"
   },
   "outputs": [],
   "source": [
    "# you can even mix numpy arrays in tf computations\n",
    "z + np.linspace(0, 4, 4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3aZJFx3qfHl8"
   },
   "source": [
    "### Training with tf.eager\n",
    "\n",
    "Eager execution has it's own API for automatic gradients. It's called GradientTape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eWk-Zb7agiHM",
    "outputId": "281e1e24-9b50-4d4a-f989-7668e137854e"
   },
   "outputs": [],
   "source": [
    "x = tf.Variable([3.0, 5.0]) \n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x * x \n",
    "    dy_dx = tape.gradient(y, x)\n",
    "\n",
    "print('gradients:', dy_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nb4WGLJrh4V4"
   },
   "source": [
    "Now let's train some networks. As usual, we'll use keras functional API for the ease of execution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Qoh6R1hxkctm",
    "outputId": "26a6dae1-c03b-4bd0-c5f5-0bb8ce50f5e8"
   },
   "outputs": [],
   "source": [
    "from keras.datasets.mnist import load_data\n",
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "X_train, X_test = X_train.astype('float32') / 255., X_test.astype('float32') / 255.\n",
    "y_train, y_test = y_train.astype('int32'), y_test.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sZYVbIQJfEjh"
   },
   "outputs": [],
   "source": [
    "keras, L = tf.keras, tf.keras.layers # use these and not just import keras\n",
    "\n",
    "model = keras.models.Sequential([ \n",
    "    L.InputLayer(X_train.shape[1:]), L.Flatten(), L.Dense(100), L.Activation('relu'), L.Dense(10) \n",
    "])\n",
    "opt = tf.train.AdamOptimizer(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "mUYwr1jMgFA7",
    "outputId": "48fd9140-0d5b-4a4d-d12e-7ed4f514e0c5"
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    batch = np.random.randint(0, len(X_train), size=100)\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(X_train[batch])\n",
    "        loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=y_train[batch], logits=logits)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        \n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        opt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "      \n",
    "    if i % 100 == 0:\n",
    "        print('step %i, loss=%.3f' % (i, loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pISE0B6TgcpS",
    "outputId": "4c4e2df0-40f5-4cf5-8e04-d305f0123e2a"
   },
   "outputs": [],
   "source": [
    "# we can now evaluate our model using any external metrics we want\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_pred = model(X_test).numpy().argmax(-1)\n",
    "print(\"Test acc:\", accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U0c-slqmdxDB"
   },
   "source": [
    "RTFM:\n",
    "* [tf.eager basics](https://www.tensorflow.org/tutorials/eager/eager_basics)\n",
    "* [tape-based gradients](https://www.tensorflow.org/tutorials/eager/automatic_differentiation)\n",
    "* [training walkthrough](https://www.tensorflow.org/tutorials/eager/custom_training_walkthrough)\n",
    "* You can also embed eager code into normal tensorflow graph with [tf.contrib.eager.py_func](https://www.tensorflow.org/guide/eager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v42w8LE4kxHk"
   },
   "outputs": [],
   "source": [
    "# Please restart the notebook again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yOW_ml2G6-wP"
   },
   "source": [
    "### 2. Tensorboard\n",
    "\n",
    "If you run more than one experiment, you will eventually have to compare your results. We've already mentioned that this can be done with tensorboard. Ideally, you wanna obtain something like this:\n",
    "\n",
    "![img](https://raw.githubusercontent.com/yandexdataschool/nlp_course/master/resources/lm_acc1.png)\n",
    "\n",
    "_except the training is not finished_\n",
    "\n",
    "If you're not into tensorflow [visdom](https://github.com/facebookresearch/visdom), [tensorboardX](https://github.com/lanpa/tensorboardX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbFYWIEhdxDn"
   },
   "source": [
    "### 3. Tensorflow Hub\n",
    "\n",
    "Most deep learning applications nowadays depend on some kind of pre-trained network to start from. Be it \n",
    "\n",
    "Keras [applications](https://keras.io/applications/) for computer vision, [gensim](https://github.com/RaRe-Technologies/gensim) for embeddings, and many smaller model zoos dedicated to every particular topic.\n",
    "\n",
    "One such model zoo is Tensorfow Hub, featuring several hot NLP models:\n",
    "* [Universal Sentence Encoder](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/semantic_similarity_with_tf_hub_universal_encoder.ipynb#scrollTo=MSeY-MUQo2Ha)\n",
    "* [ELMO](https://tfhub.dev/google/elmo/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zwWe_EMPwDWr",
    "outputId": "4b2a27c3-8dfb-49e7-b4cf-45ce04277a58"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "!pip3 install --quiet tensorflow-hub\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "model = hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder/2\")\n",
    "sess.run([tf.global_variables_initializer(), tf.tables_initializer()]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "S4bG-xzSwad2",
    "outputId": "00785144-da77-4b8e-a345-ac17d6f9c8f4"
   },
   "outputs": [],
   "source": [
    "sentence_embs = model([\"A cat sat on a mat.\", \"I am the monument to all your sins\"])\n",
    "\n",
    "print(sess.run(sentence_embs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HDCRnWihdxD4"
   },
   "source": [
    "## Part III. Worst practices\n",
    "\n",
    "There's a number of things about TF that kind of... ~~sucks~~ in need of improvement.\n",
    "\n",
    "Don't get me wrong, they are all great for their job. Except they can easily be misused with dramatic consequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_fAtXUS2lLXZ"
   },
   "source": [
    "__#1. TF.contrib is a mess__\n",
    "\n",
    "Tensorflow [contrib](https://www.tensorflow.org/api_docs/python/tf/contrib) is a place where tensorflow holds dozens of sub-libraries dedicated to everything. You name it:\n",
    "* Helper functions for sequence-to-sequence models - [check!](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq)\n",
    "* Wrapper modules for CUDNN RNN operations - [check!](https://github.com/tensorflow/probability)\n",
    "* A full-blown deep learning library? - [check](https://www.tensorflow.org/api_docs/python/tf/contrib/keras)-[check](https://www.tensorflow.org/api_docs/python/tf/contrib/slim)-[check](https://www.tensorflow.org/api_docs/python/tf/contrib/learn)!\n",
    "\n",
    "The catch is that most of the code in tf.contrib was built by independent authors. Sometimes it's poorly supported. Sometimes it's outdated. And it is definitely not designed for full compatibility with one another.\n",
    "\n",
    "For instance LSTM cells from tf.contrib.rnn are not guaranteed to work with tf.keras abstractions. And neither do tf.slim layers fit into keras models.\n",
    "\n",
    "There's a rule of thumb: if the functionality you need is in both tf core and tf.contrib, pick tf core. If it's only in tf.contrib - read through it and maybe play with it on a toy task before integrating it into your larger projects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Z9teeg963wV"
   },
   "source": [
    "__#2. Pythonic and symbolic loops__\n",
    "\n",
    "\n",
    "Sometimes you want your tensorfow graph to contain loops. The most obvious example is RNN.\n",
    "\n",
    "Tensorflow allows you to define such loops with primitives like [tf.while_loop](https://www.tensorflow.org/api_docs/python/tf/while_loop) and [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan).\n",
    "\n",
    "If you read the docs, you'll also see other primitives like __tf.map_fn__ and __tf.cond__. It is tempting to use those operations to write python-style code. \n",
    "\n",
    "__But you shouldn't__. Or rather, try hard to have as few of them as possible. Each iteration of symbolic loop introduces a gigantic overhead in computation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N_smf6wC2QNE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "x_ph = tf.placeholder_with_default(np.linspace(-10, 10, 10**4).astype('float32'), [None])\n",
    "\n",
    "\n",
    "my_square = tf.map_fn(lambda x_i: x_i ** 2, x_ph)\n",
    "my_sum_squares = tf.scan(lambda ctr, x_i: ctr + x_i, elems=my_square, initializer=0.0)[-1]\n",
    "\n",
    "\n",
    "tf_square = x_ph ** 2\n",
    "tf_sum_squares = tf.reduce_sum(tf_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "US7g8EgjGBzA",
    "outputId": "eb1a2126-84b6-4fe7-e033-3904c5e5a478"
   },
   "outputs": [],
   "source": [
    "print(\"Symbolic loops:\")\n",
    "%time print(sess.run(my_sum_squares))\n",
    "print(\"Vector operations:\")\n",
    "%time print(sess.run(tf_sum_squares))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_EVgBKMoKD62"
   },
   "source": [
    "__TL;DR:__ use control flow ops sparingly. Few large iterations are okay, many small iterations are not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8coqCX2y2RFF"
   },
   "source": [
    "__#3. Control Dependencies__ \n",
    "\n",
    "By default, if your tensorflow graph has two parallel branches of code, there's no way of telling which branch will be executed first. This can cause inconveniences. You may want to explicitly tell tensoflow \"Run this op before that one\" to save memory or make debug logs prettier.\n",
    "\n",
    "However, you can also use control dependencies to mutate graph state in the middle of execution. DON'T DO THAT unless you absolutely have to. \n",
    "\n",
    "And even then __DON'T DO THAT__.\n",
    "\n",
    "Here's a demotivational example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "suhWlwSQdxD7",
    "outputId": "1229a7aa-cbbf-4792-d393-f827de4209d2"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "x = tf.Variable(1.0)\n",
    "\n",
    "y1 = x ** 2\n",
    "\n",
    "add_first = tf.assign_add(x, 1)\n",
    "\n",
    "with tf.control_dependencies([add_first, y1]):\n",
    "  y2 = x ** 2\n",
    "  \n",
    "  add_second = tf.assign_add(x, 1)\n",
    "  with tf.control_dependencies([y2, add_second]):\n",
    "    y3 = x ** 2\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('First run:', sess.run([y1, y2, y3]))\n",
    "\n",
    "print('Second run:', sess.run([y1, y2, y3]))\n",
    "\n",
    "# Bonus quest: change as few lines as possible to make it print [1, 4, 9], [9, 16, 25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "29NgxdwgdxEL"
   },
   "source": [
    "## Part IV: cool stuff that didn't make it into tutorial\n",
    "* [tf.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) - an advanced tool for loading and managing data.\n",
    "* Creating new tf ops - [in c++](https://www.tensorflow.org/extend/adding_an_op)\n",
    "* Managing gradient computation with [tf.stop_gradient](https://github.com/tensorflow/fold) and [gradient override map](https://stackoverflow.com/questions/41391718/tensorflows-gradient-override-map-function)\n",
    "* [Gradient checkpointing](https://github.com/openai/gradient-checkpointing/) to backprop through large models in low memory\n",
    "* Tensorflow is available in many other languages. For instance, here's [tf for javascript](https://js.tensorflow.org/) or [tutorial on exporting keras model for an android app](https://medium.com/@thepulkitagarwal/deploying-a-keras-model-on-android-3a8bb83d75ca)\n",
    "* Efficient gpu parallelism with [horovod](https://github.com/uber/horovod)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5SS2CNHdxDR"
   },
   "source": [
    "### [if we have time] XLA: Tensorflow, compiled\n",
    "\n",
    "While tf.eager gives you the freedom to experiment, eventually you'll figure out exactly what you want and you'll need your code to run... faster. Preferably much faster. And on half as much gpu memory so you can increase batch size.\n",
    "\n",
    "Your typical neural network has a lot of operations that are fast to compute but require allocating large  amounts of memory. Consider adding bias element-wise to a large tensor and then applying nonlinearity. These operations can be _fused_ together: you don't allocate new memory but perform everything in-place as a single operation.\n",
    "\n",
    "__Warning:__ XLA become included by default starting from tf 1.12; earlier versions will require compiling tensorflow manually **with** XLA support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iBIJhzik79zQ"
   },
   "outputs": [],
   "source": [
    "# Please restart notebook and make sure you use tensorflow with GPU. \n",
    "# If you don't, the code will work but it XLA will give no performance boost\n",
    "# and actually run slower.\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "keras = tf.contrib.keras\n",
    "L = tf.contrib.keras.layers\n",
    "\n",
    "assert tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3njaBsgPdxDU"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2uuxpaP3dxDd"
   },
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(L.InputLayer([None, 256]))\n",
    "    model.add(L.SimpleRNN(256, return_sequences=True))\n",
    "    model.add(L.SimpleRNN(256))\n",
    "    model.add(L.Dense(100))\n",
    "    \n",
    "    x = tf.placeholder_with_default(np.random.randn(1, 1000, 256).astype('float32'), [None, None, 256])\n",
    "    pred = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mp9VrQn9la-T"
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(pred);  # \"warmup run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8cmGaRRul0kT",
    "outputId": "02321c1b-7603-4774-fab8-7dd487812207"
   },
   "outputs": [],
   "source": [
    "%timeit sess.run(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "by9GNerLdxDk"
   },
   "source": [
    "__RTFM:__ [XLA jit](https://www.tensorflow.org/performance/xla/jit)\n",
    "\n",
    "__What to expect:__ many small ops (lstm steps, dropout and batchnorm, etc) on GPU = large improvement. Few large ops (vgg16, large batch) or CPU = no improvement"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tf_tutorial_advanced.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
