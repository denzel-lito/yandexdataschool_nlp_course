{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras: как приручить карася\n",
    "\n",
    "[__`Keras`__](https://keras.io/) - это библиотека для тех случаев, когда вам нужно быстро написать нейросеть без выкрутасов. И чтобы работала.\n",
    "\n",
    "Если вы не хотите писать свои неповторимые архитектуры или угарать по нестандартным функциям потерь, keras позволит вам написать и обучить модель за 5 минут. Следите за руками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras, keras.layers as L\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer(input_shape=[64]))\n",
    "model.add(L.Dense(100, activation='relu'))\n",
    "model.add(L.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` Создаём модель из __[`keras.models`](https://keras.io/models/about-keras-models/)__ – класс нейросети. \n",
    "   * __Sequential__ – модель в которой слои применяются ко входу последовательно.\n",
    "\n",
    "\n",
    "`2.` Накидываем в модель слои из __[`keras.layers`](https://keras.io/layers/about-keras-layers/)__\n",
    "   * В керасе есть набор стандартных слоёв для построения свёрточных и рекуррентных сетей: полносвязные слои, свёртки, pooling, lstm и пр. А если нет – можно [самому сделать](https://keras.io/layers/writing-your-own-keras-layers/#writing-your-own-keras-layers).\n",
    "\n",
    "`3.` Описываем процесс обучения модели, __[`model.compile`](https://keras.io/getting-started/sequential-model-guide/#compilation)__\n",
    "   * Указывается функция потерь и метод оптимизации. Есть ещё множество дополнительных параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# что мы наворотили\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После этого модель ведёт себя как любая модель из scikit-learn. fit, predict, всё как вы любите."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "X, y = load_digits(return_X_y=True)\n",
    "\n",
    "model.fit(X, y, epochs=3)\n",
    "\n",
    "y_pred = model.predict_classes(X)\n",
    "y_proba = model.predict_proba(X)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"\\nAccuracy = %.3f\" % accuracy_score(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А ещё у неё есть куча дополнительных возможностей. Например, сериализация обученной модели.\n",
    " * ```model.save(\"./saved_model.npz\") ``` — сохранение модели вместе с весами\n",
    " * ```keras.models.load_model('./saved_model.npz`) ``` — загрузить обученную модель\n",
    " * ```model.train_on_batch ``` — сделать один шаг по градиенту на одном батче \n",
    " * ```model.input_shape, model.output_shape ``` — размеры тензоров на входе и выходе сети "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Keras functional API\n",
    "Вы также можете задавать более сложные модели на keras, строя граф из слоёв.\n",
    "\n",
    "Разберём простой пример, в котором сеть содержит два параллельных полносвязных слоя, которые собираются вместе для вычисления выхода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_inp = L.Input(shape=[64], name='input_features')\n",
    "\n",
    "l_dense1 = L.Dense(50, activation='relu')(l_inp)\n",
    "l_dense2 = L.Dense(50, activation='elu')(l_inp)\n",
    "\n",
    "l_combined = L.Concatenate()([l_dense1, l_dense2])\n",
    "\n",
    "l_out = L.Dense(10, activation='softmax')(l_combined)\n",
    "\n",
    "model = keras.models.Model(inputs=[l_inp], outputs=[l_out])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели, созданные таким образом, можно использовать также как и sequential - у них есть fit, predict, save и прочие вкусности.\n",
    "\n",
    "Более подробно можно почитать [тут](https://keras.io/getting-started/functional-api-guide/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Keras + TensorFlow\n",
    "\n",
    "Под капотом слои Keras написаны на TF (хотя вы можете выбрать другой фреймворк), и это даёт свои преимущества.\n",
    "\n",
    "Предположим, вы хотите написать хитрую функцию потерь на tensorflow, но испольовать её вы хотите вместе с обычной моделью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sess = keras.backend.get_session()\n",
    "# или sess = tf.InteractiveSession(), см. ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder('float32', [None, 64])\n",
    "\n",
    "y_pred = model(x)\n",
    "\n",
    "sess.run(y_pred, {x: X[:1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__Грабли:__ в tensorflow может одновременно быть несколько сессий. Если вы используете keras, то все вычисления он будет делать в своей сессии : `keras.backend.get_session()`\n",
    "\n",
    "__Почему это важно:__ когда вы говорите model.fit(...), веса нейронки обучаются в сессии кераса. Если у вас есть другие сессии (например, tf.InteractiveSession), в них никакого обучения не происходит, переменные даже не инициализированы.\n",
    "\n",
    "Например, если сейчас позвать ```tf.InteractiveSession().run(y_pred, {x: X[:1]}))```, то tf ругнётся, что у него не инициализиованы веса модели.\n",
    "\n",
    "__А можно проще?:__ если работаете в керасе, используйте `sess = keras.backend.get_session()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Surely You're Joking, Mr. Keras\n",
    "\n",
    "Давайте разберём несколько архитектур на керасе. Попытайтесь понять, что с ними не так."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Задача:__ Предсказать цену дома в $mil\n",
    "* __Вход:__ 39 признаков этого дома"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([39]))\n",
    "model.add(L.BatchNormalization())\n",
    "model.add(L.Dense(128, kernel_initializer=keras.initializers.zeros()))\n",
    "model.add(L.Dense(128, kernel_initializer=keras.initializers.zeros()))\n",
    "model.add(L.Dense(1))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spoiler!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([39]))\n",
    "model.add(L.BatchNormalization())                         \n",
    "# ^ лучше нормализовать входы (не ошибка)\n",
    "\n",
    "model.add(L.Dense(128, kernel_initializer=keras.initializers.zeros()))\n",
    "# ^ полносвязный слой без нелинейности (нейросеть не лучше линейной регрессии)\n",
    "model.add(L.Dense(128, kernel_initializer=keras.initializers.zeros()))\n",
    "# ^ так ещё и инициализируется нулями (эффект симметрии, нейроны будут одинаковыми)\n",
    "model.add(L.Dense(1))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error') \n",
    "# ^ попробовать relative mse, log-mse (не ошибка)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Задача:__ Распознать рукописную цифру (0-9)\n",
    "* __Вход:__ картинка 28 x 28 пикселей (ч/б)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([28, 28, 1]))\n",
    "model.add(L.Conv2D(filters=512, kernel_size=(3, 3)))\n",
    "model.add(L.Activation('relu'))\n",
    "model.add(L.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(L.Flatten())\n",
    "model.add(L.Dense(100))\n",
    "model.add(L.Activation('relu'))\n",
    "model.add(L.Dropout(0.1))\n",
    "model.add(L.Dense(10))\n",
    "model.add(L.Activation('softmax'))\n",
    "model.add(L.Dropout(0.1))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spoiler!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([28, 28, 1]))\n",
    "model.add(L.Conv2D(filters=512, kernel_size=(3, 3)))\n",
    "# ^ многовато фильтров, вряд ли найдётся 512 значимо разных 3x3 карты\n",
    "model.add(L.Activation('relu'))\n",
    "model.add(L.MaxPool2D(pool_size=(2, 2)))\n",
    "# ^ relu и max pool можно переставить местами, будет то же самое чуть быстрее (не ошибка)\n",
    "model.add(L.Flatten())\n",
    "model.add(L.Dense(100))\n",
    "model.add(L.Activation('relu'))\n",
    "model.add(L.Dropout(0.1)) # < хороший, годный дропаут\n",
    "model.add(L.Dense(10))\n",
    "model.add(L.Activation('softmax'))\n",
    "model.add(L.Dropout(0.1))\n",
    "# ^ не стоит dropout-ить вероятности на выходе, рискуете получить бесконечный лосс\n",
    "model.compile(optimizer='rmsprop', loss='mean_squared_error')\n",
    "# ^ обучать классификацию по квадратичной ошибке можно, но... это безбожно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Задача:__ тэгировать твиты: __Offensive, Illegal, Bot__. Твит может иметь несколько тэгов.\n",
    "* __Вход:__ текст, каждое слово закодировано номером в словаре: от 1 до 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(L.InputLayer([None]))\n",
    "model.add(L.Embedding(input_dim=10000, output_dim=128))\n",
    "model.add(L.Conv1D(filters=64, kernel_size=3))\n",
    "model.add(L.Activation('softmax'))\n",
    "model.add(L.GlobalMaxPool1D())\n",
    "model.add(L.Dense(128))\n",
    "model.add(L.Activation('softmax'))\n",
    "model.add(L.Dense(3))\n",
    "model.add(L.Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spoiler!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(L.InputLayer([None]))\n",
    "model.add(L.Embedding(input_dim=10000, output_dim=128))\n",
    "model.add(L.Conv1D(filters=64, kernel_size=3))\n",
    "model.add(L.Activation('softmax'))\n",
    "# ^ softmax плохо подходит для промежуточной нелинейности (почти все нейроны будут близки к 0)\n",
    "model.add(L.GlobalMaxPool1D())\n",
    "model.add(L.Dense(128))\n",
    "model.add(L.Activation('softmax'))\n",
    "# ^ и тут тоже\n",
    "model.add(L.Dense(3))\n",
    "model.add(L.Activation('softmax'))\n",
    "# ^ должна быть сигмоида, поскольку твит может одновременно принадлежать нескольким классам\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Задача:__ классификация одежды (10 классов)\n",
    "* __Вход:__ картинка RGB 100 x 100 пикселей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([100, 100, 3]))\n",
    "\n",
    "for filters in [32, 64, 128, 256]:\n",
    "    model.add(L.Conv2D(filters, kernel_size=(5, 5)))\n",
    "    model.add(L.Conv2D(filters, kernel_size=(1, 1)))\n",
    "    model.add(L.MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(L.Activation('relu'))\n",
    "    model.add(L.BatchNormalization())\n",
    "\n",
    "model.add(L.Flatten())\n",
    "\n",
    "model.add(L.Dense(100, activation='relu'))\n",
    "model.add(L.Dropout(0.5))\n",
    "model.add(L.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spoiler!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([100, 100, 3]))\n",
    "\n",
    "for filters in [32, 64, 128, 256]:\n",
    "    # ^ на четвёртой итерации вход станет меньше 5x5, свёртка \"не влезет\"\n",
    "    model.add(L.Conv2D(filters, kernel_size=(5, 5)))\n",
    "    model.add(L.Conv2D(filters, kernel_size=(1, 1)))\n",
    "    # ^ свёртка 1x1 имела бы смысл, если бы перед ней была нелинейность\n",
    "    model.add(L.MaxPooling2D(pool_size=(3, 3)))\n",
    "    model.add(L.Activation('relu'))\n",
    "    model.add(L.BatchNormalization())\n",
    "    # ^ не ошибка, но рекоммендуют вставлять BatchNorm перед активацией\n",
    "\n",
    "model.add(L.Flatten())\n",
    "\n",
    "model.add(L.Dense(100, activation='relu'))\n",
    "model.add(L.Dropout(0.5))\n",
    "model.add(L.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_accuracy')\n",
    "# accuracy имеет нулевую производную, поэтому оптимизировать лучше кроссэнтропию\n",
    "# (sparse_categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Обучим что-нибудь\n",
    "\n",
    "Давайте пройдём процесс обучения нейронной сети от сбора данных до "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_train = X_train.reshape([-1, 28, 28, 1])\n",
    "X_test =  X_test.reshape([-1, 28, 28, 1])\n",
    "\n",
    "\n",
    "print(\"Input shape:\", X_train.shape)\n",
    "print(\"Input range:\", np.min(X_train), '-', np.max(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(12):\n",
    "    plt.subplot(2, 6, i + 1)\n",
    "    plt.imshow(X_train[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(y_train[i])\n",
    "    plt.xticks([]); plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer([28, 28, 1]))\n",
    "model.add(L.Flatten())\n",
    "model.add(L.Dense(512, activation='relu'))\n",
    "model.add(L.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', \n",
    "              metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=10, validation_data=[X_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Что-то сломалось...__\n",
    "\n",
    "Есть идеи, что не так?\n",
    "\n",
    "_hint:_ данные неплохо бы привести в [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "<Your absolutely awesome convolutional network>\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', \n",
    "              metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=512, epochs=100, validation_data=[X_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "augmenter = ImageDataGenerator(\n",
    "    rotation_range=10, # degrees\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "augmenter.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = augmenter.flow(np.repeat(X_train[:1], 12, axis=0), batch_size=12).next()\n",
    "\n",
    "plt.figure(figsize=[12, 4])\n",
    "for i in range(12):\n",
    "    plt.subplot(2, 6, i + 1)\n",
    "    plt.imshow(sample[i].reshape(28, 28), cmap='gray')\n",
    "    plt.xticks([]); plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "<Your absolutely awesome convolutional network>\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', \n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "model.fit_generator(augmenter.flow(X_train, y_train, batch_size=512),\n",
    "                    epochs=100, validation_data=[X_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Зоопарк моделей\n",
    "\n",
    "У карася также есть свой маленький пруд с предобученными моделями: `keras.applications`. Как правило, это классификаторы изображений, обученные на выборке [ImageNet](http://image-net.org/) - около 1.3kk изображений. Давайте заценим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import keras, keras.layers as L\n",
    "import keras.applications as zoo\n",
    "\n",
    "classes = pickle.load(open('classes.pkl','rb'))\n",
    "model = zoo.InceptionV3(include_top=True, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "def predict_top10(img):\n",
    "    img = resize(img, (299, 299), mode='reflect')\n",
    "    assert img.min() >= 0.0 and img.max() <= 1.0\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    img_preprocessed = zoo.inception_v3.preprocess_input(img[None] * 255)\n",
    "    probs = model.predict(img_preprocessed)[0]\n",
    "    labels = probs.argsort()[-1:-10:-1]\n",
    "\n",
    "    print('top-10 classes:')\n",
    "    for l in labels:\n",
    "        print('%.4f\\t%s' % (probs.ravel()[l], classes[l].split(',')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_top10(plt.imread('sample_images/albatross.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget http://cdn.com.do/wp-content/uploads/2017/02/Donal-Trum-Derogar.jpeg -O img.jpg\n",
    "predict_top10(plt.imread('img.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Внимание:__ InceptionV3 требует много памяти для работы. Если ваш ПК начинает зависать,\n",
    "* закройте ~~ютюб и сериальчики~~ все программы кроме jupyter и браузера с одной вкладкой\n",
    "* если не помогло, загрузите эту тетрадку в [google colab](https://colab.research.google.com/) и работайте там\n",
    "\n",
    "Ещё можно попробовать заменить `zoo.InceptionV3` на `zoo.MobileNet`. Вам также придётся исправить предобработку картинки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. (Optional) Немного RNN-ок\n",
    "\n",
    "Карась великодушно позволяет вам обучать рекуррентные сети с таким же интерфейсом, что и свёрточные. Рекуррентный слой применяется сразу ко всей последовательности входов.\n",
    "\n",
    "Для примера решим задачу классификации отзывов на фильмы с IMDB: дан текст отзыва, разбитый на слова; нужно предсказать оценку: __\"1\"__  - положительный , __\"0\"__ - отрицательный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждое слово в данных закодировано уникальным номером в словаре из 5000 наиболее частых слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = imdb.get_word_index()\n",
    "print([voc.get(word, 0) for word in \"i absolutely loved the movie for its honesty\".split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Особенность работы с текстами в том, что все примеры имеют разную длину. Чтобы собрать их в одну матрицу, давайте выберем некоторую целевую длину.\n",
    "Дополним слишком короткие последовательности до неё нулями и обрежем слишком длинные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "x_train = pad_sequences(x_train, maxlen=100)\n",
    "x_test = pad_sequences(x_test, maxlen=100)\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последовательности внутри keras представлены в формате 3-мерных тензоров: __`[batch_size, length, channels]`__. Например, последовательность 100-мерных векторов word2vec для двух предложений до 12 слов каждое будут иметь форму `[2, 12, 100]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(L.InputLayer(input_shape=[None]))\n",
    "\n",
    "model.add(L.Embedding(5000, 128))\n",
    "\n",
    "model.add(L.LSTM(64, return_sequences=True, recurrent_dropout=0.2))\n",
    "\n",
    "model.add(L.GlobalMaxPool1D())\n",
    "\n",
    "model.add(L.Dense(2, activation='softmax'))\n",
    "\n",
    "model.compile('adam', loss='sparse_categorical_crossentropy', \n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=3, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "y_test_probs = model.predict_proba(x_test, verbose=True)[:, 1]\n",
    "print(\"Test scores:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_probs > 0.5))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_test_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"i really loved that movie . the plot was thrilling , the visual effects were just astonishing .\"\n",
    "xi = np.array([[voc.get(word, 0) for word in example.lower().split()]])\n",
    "print(xi)\n",
    "print(\"P(positive | x) = %.3f\" % model.predict_proba(xi)[:, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
