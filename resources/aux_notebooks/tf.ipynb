{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "\n",
    "![img](https://lh3.googleusercontent.com/I1Dpp7I9RZIGl0rVMlPfnhfl-bkl_2uDHZwVC87BWmqtPaAs1irMWOdJxTmTEQJB-VGfLryCyHxqvyNchVIVLL-vqGrF3Q=s688)\n",
    "\n",
    "В этом семинаре мы познакомимся с [Tensorflow](https://www.tensorflow.org/) и напишем на нём что-нибудь машинно-обучаемое.\n",
    "\n",
    "__[Если вы работаете локально]__ Устанавливаем tensorflow:\n",
    "* `pip install tensorflow` хватит на первое время\n",
    "* Если вы хотите поддержку GPU или  TF специально собранный под ваш процессор, вам [сюда](https://www.tensorflow.org/install/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# все вычисления в tf происходят в сессии: \"сессия.посчитай_мне(вот_это)\"\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разогрев: __numpy__ vs __tensorflow__\n",
    "\n",
    "__Задание:__ напишите (на numpy) функцию, которая вычисляет __сумму квадратов чисел от 0 до `N - 1`__ (включительно).\n",
    "\n",
    "_hint: numpy.arange_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def sum_squares_np(N):\n",
    "    # сумма квадратов чисел от 0 до N - 1 \n",
    "    result = # YOUR CODE\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sum_squares_np(10**8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь напишем то же самое на TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"место куда я потом подставлю чиселку N\"\n",
    "N = tf.placeholder('int64', name=\"my_input_N\")\n",
    "\n",
    "# \"рецепт получения ответа, если у вас есть N\"\n",
    "result = tf.reduce_sum((tf.range(N)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Сессия, посчитай мне `result`. Подставь `N=10^8`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(sess.run(result, {N: 10**8}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__hint:__ рецепты можно и нужно использовать повторно, подставляя разные входы. Начиная со второго вызова рецепт будет выполняется быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Графы вычислений\n",
    "\n",
    "Работа в TensorFlow состоит из двух частей: \n",
    "\n",
    "1. __создание графа__ вычислений (в примере выше: `N` и `result`)\n",
    "2. использование этого графа для __вычислений__, уже с конкретными числами (sess.run(...))\n",
    "\n",
    "Давайте разберёмся в каждом из них отдельно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание графа вычислений обычно начинается с точек входа: __[tf.placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)__. Суть placeholder-ов: __\"место, куда мы потом подставим данные\"__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"сюда можно подставлять действительное число/вектор/тензор любого размера\"\n",
    "arbitrary_input = tf.placeholder('float32')\n",
    "\n",
    "# \"целочисленный вектор (1d) любой длины\n",
    "input_vector = tf.placeholder('int32', shape=(None,))\n",
    "\n",
    "# \"только целочисленный вектор из 10 элементов\"\n",
    "fixed_size_vector = tf.placeholder('int32', shape=(10,))\n",
    "\n",
    "# Смешанные варианты. если знаете размер заранее, указывайте. \n",
    "# если рамер может изменяться - оставляйте None. \n",
    "input1 = tf.placeholder('bool', shape=(None, 100, None))\n",
    "input2 = tf.placeholder('int32', shape=(None, None, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее вы можете писать операции _(рецепты)_, применяя функции к placeholder-ам, константам и результатам других операций.\n",
    "\n",
    "Например, `tf.reduce_sum(tf.arange(N)\\**2)` это три последовательных операции от N.\n",
    "\n",
    "Синтаксис операций в tensorflow очень похож на numpy\n",
    "  * Поэлементные операции: __`a + b, a / b, a ** b, ...`__\n",
    "  * np.sin -> __tf.sin__\n",
    "  * np.mean -> __tf.reduce_mean__\n",
    "  * np.arange -> __tf.range__\n",
    "  * np.zeros -> __tf.zeros__\n",
    "  * np.random.randn -> __tf.random_normal__\n",
    "  \n",
    "После применения операции у вас получится новый тензор ([`tf.Tensor`](https://www.tensorflow.org/api_docs/python/tf/Tensor)) - узел графа вычислений, который можно использовать в новых операциях. \n",
    "Да, кстати, `tf.placeholder` это тоже тензор.\n",
    "  \n",
    "Полный список операций можно найти в [доках](https://www.tensorflow.org/api_docs/python), но пока лучше просто полагайтесь на __tab__ и __shift+tab__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# операция \"умножь каждый элемент на 2\"\n",
    "double_the_vector = input_vector * 2\n",
    "\n",
    "# косинус поэлементной суммы\n",
    "elementwise_cosine = tf.cos(tf.to_float(input_vector + fixed_size_vector))\n",
    "\n",
    "# ещё пример\n",
    "noise = tf.random_normal(tf.shape(arbitrary_input))\n",
    "output = arbitrary_input ** 2 - tf.reduce_mean(arbitrary_input) * noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь вы можете использовать получившийся граф операций, чтобы что-нибудь посчитать.\n",
    "\n",
    "  * __```sess.run(output_or_outputs, {placeholder1: value1, placeholder2: value2})```__ - рекомендованный способ.\n",
    "  * __```output.eval({placeholder:value})```__ - для отладки, вычисляет один тензор (число, вектор, матрицу, ...) в [дефолтной сессии](https://www.tensorflow.org/api_docs/python/tf/get_default_session).\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('output on scalar', sess.run(output, {arbitrary_input: 3.1415926}))\n",
    "print('output on vector', sess.run(output, {arbitrary_input: np.ones(5)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Hint:__ если у вас несколько связанных выходов, лучше вычислять их вместе, чтобы избежать повторных вычислений:\n",
    "  * ```a, b = sess.run([output1, output2], {placeholder: value})```\n",
    "  * ```a_dict, b = sess.run(({'a': output1, 'b': output2}, output3), {placeholder:value})```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1: polar pretzels\n",
    "_inspired by [this post](https://www.quora.com/What-are-the-most-interesting-equation-plots)_\n",
    "\n",
    "Есть в тригонометрии класс функций с забавными графиками. Вот пример:\n",
    "\n",
    "$$ x(t) = t - 1.5 * cos( 15 t) $$\n",
    "$$ y(t) = t - 1.5 * sin( 16 t) $$\n",
    "\n",
    "__задание:__ реализуйте вычисление этой функции на tensorflow (см. ниже)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = tf.placeholder('float32')\n",
    "\n",
    "\n",
    "x = ###YOUR CODE\n",
    "y = ###YOUR CODE\n",
    "\n",
    "\n",
    "x_points, y_points = sess.run([x, y], {t: np.linspace(-10, 10, num=10000)})\n",
    "plt.plot(x_points, y_points);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы уже выполнили задание, предлагаем\n",
    "* поиграться с параметрами кренделя\n",
    "* работа с размерностями в TF - [тут](https://gist.github.com/justheuristic/138fde49b32ec59f2d80298f6959d5ab#file-md)\n",
    "* визуализация TFных графов - [тут](https://gist.github.com/justheuristic/138fde49b32ec59f2d80298f6959d5ab#file-tensorboard-md)\n",
    "\n",
    "\n",
    "А ещё есть длинная, но очень клёвая подборка советов [effective tensorflow](https://github.com/vahidk/EffectiveTensorflow#effective-tensorflow) - но лучше читать его уже после семинара."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2: mean squared error\n",
    "Вычислите MSE по 2 векторам. На этот раз вам нужно написать не только граф, но и само вычисление."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  v--- постройте граф (placeholder-ы и операции, которые вычисляют MSE)\n",
    "<...>\n",
    "\n",
    "\n",
    "def compute_my_mse(y_target, y_predicted):\n",
    "    return <вычислите mse для конкретных входов, используя sess.run>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Тесты\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for n in [1, 5, 10, 10 ** 3]:\n",
    "    \n",
    "    elems = [np.arange(n), np.arange(n,0,-1), np.zeros(n),\n",
    "             np.ones(n), np.random.random(n), np.random.randint(100,size=n)]\n",
    "    \n",
    "    for el in elems:\n",
    "        for el_2 in elems:\n",
    "            true_mse = np.array(mean_squared_error(el, el_2))\n",
    "            my_mse = compute_my_mse(el, el_2)\n",
    "            if not np.allclose(true_mse, my_mse):\n",
    "                print('Ошибка:')\n",
    "                print('mse(%s,%s)' % (el,el_2))\n",
    "                print(\"должно быть: %f, получилось: %f\" % (true_mse, my_mse))\n",
    "                raise ValueError(\"Что-то не так\")\n",
    "\n",
    "print(\"Все тесты пройдены!\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Переменные (Variables)\n",
    "\n",
    "[`tf.placeholder`](https://www.tensorflow.org/api_docs/python/tf/placeholder)-ы удобны, когда вы хотите подставлять новые данные в ваш граф при каждом вызове ```sess.run```. Если вы хотите, чтобы какая-то переменная всегда имела значение (например, веса нейронной сети), которое вы могли бы изменять когда сочтёте нужным, для вас есть переменные [`(tf.Variable)`](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "* Переменные сами хранят численное значение;\n",
    "* Вы можете в любой момент изменить значение переменной;\n",
    "* Переменные можно использовать в операциях, также как и placeholder-ы.\n",
    " \n",
    "Больше про то, как работают переменные - [тык](https://www.tensorflow.org/guide/variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# создать новую переменную\n",
    "my_variable = tf.Variable(initial_value=np.arange(5, dtype='float32'))\n",
    "\n",
    "# операция над переменной\n",
    "variable_squared = my_variable ** 2\n",
    "\n",
    "# присвоить всем переменным их initial_value\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"value :\", sess.run(my_variable))\n",
    "print(\"square:\", sess.run(variable_squared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# задать значение переменной вручную\n",
    "sess.run(my_variable.assign(np.arange(5, 10, 1)))\n",
    "\n",
    "print(\"value :\", sess.run(my_variable))\n",
    "print(\"square:\", sess.run(variable_squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Автоматичекие градиенты\n",
    "* Tensorflow может автоматически считать для вас частные производные: __```tf.gradients(f(x), [x])```__\n",
    "* Для этого он проходит по операциям, участвовавшим в вычислении целевого значения, и применяет chain rule, например\n",
    "$$ {\\partial \\text{tf.exp}(\\text{tf.cos}(x)) \\over \\partial x} = {\\partial \\text{tf.exp}(\\text{tf.cos}(x)) \\over \\partial \\text{tf.cos}(x)}\\cdot {\\partial \\text{tf.cos}(x) \\over \\partial x} $$\n",
    "\n",
    "* Производные всех элементарных функций (tf.exp, tf.cos, tf.reduce_sum) подставляются автоматически.\n",
    "\n",
    "Таким образом вы можете посчитать производную любого скалярного значения по любому тензору, участвующему в его вычислении. \n",
    "\n",
    "_Давайте поиграемся :)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_scalar = tf.placeholder('float32')\n",
    "\n",
    "scalar_squared = my_scalar ** 2\n",
    "\n",
    "#a derivative of scalar_squared by my_scalar\n",
    "derivative = tf.gradients(scalar_squared, [my_scalar])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-3,3)\n",
    "x_squared, x_squared_der = sess.run([scalar_squared, derivative], {my_scalar:x})\n",
    "\n",
    "plt.plot(x, x_squared,label=\"x^2\")\n",
    "plt.plot(x, x_squared_der, label=\"derivative\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Почему это круто\n",
    "\n",
    "Ниже определена функция __`weird_psychotic_function`__ от __`my_scalar`__ и __`my_vector`__. Что она делает... ой, вам лучше не знать.\n",
    "\n",
    "__ваша задача:__ вычислить производную этой функции по обоим аргументам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_vector = tf.placeholder('float32',[None])\n",
    "\n",
    "weird_psychotic_function = tf.reduce_mean((my_vector+my_scalar)**(1+tf.nn.moments(my_vector,[0])[1]) + 1./ tf.atan(my_scalar))/(my_scalar**2 + 1) + 0.01*tf.sin(2*my_scalar**1.5)*(tf.reduce_sum(my_vector)* my_scalar**2)*tf.exp((my_scalar-4)**2)/(1+tf.exp((my_scalar-4)**2))*(1.-(tf.exp(-(my_scalar-4)**2))/(1+tf.exp(-(my_scalar-4)**2)))**2\n",
    "\n",
    "# посчитайте производную функции по my_scalar и my_vector\n",
    "der_by_scalar = #YOUR_CODE_HERE\n",
    "der_by_vector = #YOUR_CODE_HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scalar_space = np.linspace(1, 7, 100)\n",
    "\n",
    "y = [sess.run(weird_psychotic_function, {my_scalar:x, my_vector:[1, 2, 3]})\n",
    "     for x in scalar_space]\n",
    "\n",
    "plt.plot(scalar_space, y, label='function')\n",
    "\n",
    "y_der_by_scalar = [sess.run(der_by_scalar, {my_scalar:x, my_vector:[1, 2, 3]})\n",
    "     for x in scalar_space]\n",
    "\n",
    "plt.plot(scalar_space, y_der_by_scalar, label='derivative')\n",
    "plt.grid()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Последний штрих: оптимизаторы (Optimizer)\n",
    "\n",
    "Чтобы вам не приходилось писать шаг градиентного спуска вручную, в TensorFlow есть зоопарк алгоритмов на оптимизации: [__`tf.train`__](https://www.tensorflow.org/api_guides/python/train). \n",
    "\n",
    "Кроме обычного SGD там есть rmsprop, adam и все-все-все - shift+tab вам в помощь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_guess = tf.Variable(np.zeros(2,dtype='float32'))\n",
    "y_true = tf.range(1,3,dtype='float32')\n",
    "\n",
    "loss = tf.reduce_mean((y_guess - y_true + tf.random_normal([2]))**2) \n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(0.05, 0.5).minimize(loss, var_list=y_guess)\n",
    "\n",
    "# те же градиенты, более подробно\n",
    "# updates = [[tf.gradients(loss,y_guess)[0], y_guess]]\n",
    "# optimizer = tf.train.MomentumOptimizer(0.05, 0.5).apply_gradients(updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "guesses = [sess.run(y_guess)]\n",
    "\n",
    "for _ in range(100):\n",
    "    sess.run(optimizer)\n",
    "    guesses.append(sess.run(y_guess))\n",
    "    \n",
    "    clear_output(True)\n",
    "    plt.plot(*zip(*guesses), marker='.')\n",
    "    plt.scatter(*sess.run(y_true), c='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализуем логистическую регрессию\n",
    "\n",
    "Прежде чем мы перейдём к нейросетям, давайте реализуем на tensorflow логистическую регрессию. Обучим её отличать рукописные \"0\" от \"1\".\n",
    "\n",
    "Если вы не помните, как работает логистическая регрессия, ~~что вы вообще здесь делаете?~~ не бойтесь, мы всё напомним."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "X, y = load_digits(2, return_X_y=True)\n",
    "\n",
    "print(\"y [shape - %s]:\" % (str(y.shape)), y[:10])\n",
    "print(\"X [shape - %s]:\" % (str(X.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('X:\\n', X[:3,:10])\n",
    "print('y:\\n', y[:10])\n",
    "plt.imshow(X[0].reshape([8,8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объявим placeholder-ы для X и y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_X = #YOUR CODE: float32 матрица\n",
    "input_y = #YOUR CODE: float32 вектор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# объявим переменную с весами. Начальное значение - 64 нуля (вектор)\n",
    "weights = #YOUR CODE\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку это бинарная классификация, будем учить лог-регрессию с сигмоидой:\n",
    "$$P(y_i | X_i) = \\sigma(W \\cdot X_i) ={ 1 \\over {1+e^{- [W \\cdot X_i]}} }$$\n",
    "\n",
    "hint: скалярное произведение $[W \\cdot X_i]$ можно посчитать при помощи `*` и [`tf.reduce_sum`](https://www.tensorflow.org/api_docs/python/tf/reduce_sum), а можно запариться и использовать [`tf.matmul`](https://www.tensorflow.org/api_docs/python/tf/matmul)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_y_proba = <predicted probabilities for input_X using weights>\n",
    "\n",
    "assert predicted_y_proba.shape.ndims == 1, \"class 1 probabilities must be 1-dimentional. consider [:, 0]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве функции потерь возьмём logloss (aka binary crossentropy, -log(likeihood)):\n",
    "$$ L = {1 \\over N} \\underset{X_i,y_i} \\sum - [  y_i \\cdot log P(y_i | X_i) + (1-y_i) \\cdot log (1-P(y_i | X_i)) ]$$\n",
    "\n",
    "Не забудьте минус :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logistic loss (scalar, mean over sample) between predicted_y_proba and input_y\n",
    "loss = # YOUR CODE HERE\n",
    "\n",
    "# теперь можно позвать tf.train.GradientDescentOptimizer как в примере выше.\n",
    "train_step = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "for i in range(5):\n",
    "    \n",
    "    loss_i, _ = sess.run([loss, train_step], ###<YOUR CODE: feed values to placeholders>)\n",
    "    \n",
    "    print(\"loss at iter %i: %.4f\" % (i, loss_i))\n",
    "    \n",
    "    print(\"train auc:\", roc_auc_score(y_train, sess.run(predicted_y_proba, {input_X: X_train})))\n",
    "    print(\"test auc:\", roc_auc_score(y_test, sess.run(predicted_y_proba, {input_X: X_test})))\n",
    "\n",
    "    \n",
    "print (\"resulting weights:\")\n",
    "plt.imshow(sess.run(weights).reshape(8, -1))\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### Дошли досюда?\n",
    "\n",
    "Значит либо вы очень круты и задания показались вам простыми, либо вы решили более подробно изучить тетрадку уже после семинара... ну либо вы просто случайно сюда промотали. В последнем случае прошу промотать обратно к нерешённым заданиям.\n",
    "\n",
    "\n",
    "Всё ещё читаете? Тогда вы сами виноваты. Будем учить многослойную нейронку.\n",
    "\n",
    "\n",
    "Сегодня в меню mnist - распознавание рукописных цифр. Но вы, вероятно, уже их где-то видели.\n",
    "* ч/б картинки 28x28 пикселей = 784 признака\n",
    "* 10 классов\n",
    "* 50k примеров для обучения\n",
    "\n",
    "Ваша задача - научить `хотя_бы_двухслойный_персептрон`, который будет их классифицировать\n",
    "\n",
    "Линейные модели на этой задаче ошибаются чуть больше, чем в __7% случаев__.\n",
    "\n",
    "__Ваша задача:__ сократить долю ошибок хотя бы до __3%__. \n",
    "\n",
    "Если слова \"свёрточная нейросеть\" вам о чём-то говорят - сразу до 1%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget https://gist.github.com/justheuristic/783144a0c0e82d829707c69240965fa9/raw/39b81ca7f8c3f4f3ce4c980540b25dc858de3020/mnist.py -O mnist.py\n",
    "from mnist import load_dataset\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "\n",
    "print (X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "вы чувствуете необъяснимое желание создавать placeholder-ы и переменные в этой клетке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "что-то подсказывает вам, что ваша нейросеть должна уметь предсказывать вероятности классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "вы вспоминаете, что можно обучаться на multiclass log loss (aka categorical crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "вы чувствуете, что вам потребуется цикл с многими итерациями обучения. голоса в голове шепчут \"используй минибатчи!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "вам кажется, что было бы неплохо отслеживать качество модели на отдельной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "только сейчас вы вспоминаете, что у вас есть ещё и тестовая выборка. почему бы не померить точность на ней?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
